# Deep-Structure RL-LNS Solver

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.2+-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/Transformers-4.40+-yellow.svg" alt="Transformers">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
</p>

> ğŸ§  ç»“åˆ **GNN ç»“æ„ç¼–ç ** ä¸ **Qwen2.5-7B å¤§è¯­è¨€æ¨¡å‹** çš„æ··åˆæ•´æ•°çº¿æ€§è§„åˆ’ (MILP) ç¥ç»æ±‚è§£å™¨ï¼Œé‡‡ç”¨ **Physics-Informed SFT** å’Œ **GRPO å¼ºåŒ–å­¦ä¹ ** è¿›è¡Œè®­ç»ƒã€‚

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#-é¡¹ç›®ç®€ä»‹)
- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„)
- [å®‰è£…æŒ‡å—](#-å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [æ•°æ®æ ¼å¼](#-æ•°æ®æ ¼å¼)
- [æ¨¡å‹æ¶æ„](#-æ¨¡å‹æ¶æ„)
- [è®­ç»ƒæµç¨‹](#-è®­ç»ƒæµç¨‹)
- [é…ç½®è¯´æ˜](#-é…ç½®è¯´æ˜)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [API æ–‡æ¡£](#-api-æ–‡æ¡£)
- [å®éªŒç»“æœ](#-å®éªŒç»“æœ)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [å¼•ç”¨](#-å¼•ç”¨)
- [è®¸å¯è¯](#-è®¸å¯è¯)

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

**RL-LNS** (Reinforcement Learning - Large Neighborhood Search) æ˜¯ä¸€ä¸ªåˆ›æ–°çš„ MILP æ±‚è§£æ¡†æ¶ï¼Œå°†æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿä¼˜åŒ–ç®—æ³•ç›¸ç»“åˆã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹ MILP é—®é¢˜ä¸­äºŒå…ƒå˜é‡çš„æœ€ä¼˜å–å€¼ï¼Œä»è€ŒåŠ é€Ÿå¤§è§„æ¨¡ç»„åˆä¼˜åŒ–é—®é¢˜çš„æ±‚è§£ã€‚

### ç ”ç©¶åŠ¨æœº

ä¼ ç»Ÿçš„ MILP æ±‚è§£å™¨ï¼ˆå¦‚ Gurobiã€CPLEXï¼‰åœ¨é¢å¯¹å¤§è§„æ¨¡é—®é¢˜æ—¶å¯èƒ½éœ€è¦æ•°å°æ—¶ç”šè‡³æ•°å¤©çš„è®¡ç®—æ—¶é—´ã€‚æœ¬é¡¹ç›®æ¢ç´¢äº†ä¸€ç§æ–°èŒƒå¼ï¼š

1. **å­¦ä¹ é—®é¢˜ç»“æ„**: é€šè¿‡ GNN ç¼–ç çº¦æŸ-å˜é‡çš„äºŒéƒ¨å›¾ç»“æ„
2. **åˆ©ç”¨ LLM æ¨ç†èƒ½åŠ›**: ä½¿ç”¨ Qwen2.5-7B ä½œä¸ºæ¨ç†éª¨å¹²
3. **ç‰©ç†çº¦æŸæ„ŸçŸ¥è®­ç»ƒ**: åœ¨æŸå¤±å‡½æ•°ä¸­æ˜¾å¼å¼•å…¥çº¦æŸæ»¡è¶³å’Œæ•´æ•°æ€§æƒ©ç½š
4. **å¼ºåŒ–å­¦ä¹ å¾®è°ƒ**: ä½¿ç”¨ GRPO ç®—æ³•è¿›ä¸€æ­¥ä¼˜åŒ–è§£çš„è´¨é‡

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ”¹ åŒæ¨¡å¼è¾“å…¥
- **GNN æ¨¡å¼**: å°† MILP é—®é¢˜ç¼–ç ä¸ºäºŒéƒ¨å›¾ï¼Œé€šè¿‡ GNN æå–ç»“æ„ç‰¹å¾
- **Text æ¨¡å¼**: å°† MILP é—®é¢˜åºåˆ—åŒ–ä¸ºæ–‡æœ¬ï¼Œæ”¯æŒè¶…é•¿åºåˆ—åˆ†å—å¤„ç†

### ğŸ”¹ å…ˆè¿›çš„æ¨¡å‹æ¶æ„
- **Qwen2.5-7B-Instruct** ä½œä¸ºæ¨ç†éª¨å¹²
- **4-bit QLoRA** é‡åŒ–ï¼Œæ”¯æŒå•å¡ 24GB æ˜¾å­˜è®­ç»ƒ
- **FlashAttention-2** åŠ é€Ÿæ³¨æ„åŠ›è®¡ç®—
- **ç¦ç”¨ RoPE**ï¼Œä½¿ç”¨ RWPE ä½ç½®ç¼–ç ä¿ç•™å›¾ç»“æ„

### ğŸ”¹ Physics-Informed è®­ç»ƒ
- **ä»»åŠ¡æŸå¤±**: äºŒåˆ†ç±»äº¤å‰ç†µ
- **çº¦æŸæŸå¤±**: æƒ©ç½šçº¦æŸè¿å
- **æ•´æ•°æ€§æŸå¤±**: æ¨åŠ¨é¢„æµ‹è¶‹å‘ 0/1

### ğŸ”¹ GRPO å¼ºåŒ–å­¦ä¹ 
- **ç»„é‡‡æ ·**: æ¯ä¸ªå®ä¾‹é‡‡æ · G=16 ä¸ªå€™é€‰è§£
- **ç›¸å¯¹ä¼˜åŠ¿**: åŸºäºç»„å†…æ’åè®¡ç®—ä¼˜åŠ¿å‡½æ•°
- **å¯è¡Œæ€§å¥–åŠ±**: æ˜¾å¼å¥–åŠ±å¯è¡Œè§£

### ğŸ”¹ å¯å‘å¼è¿›åŒ– (EOH)
- è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ– LNS ç®—å­
- æ”¯æŒå¤šç§è¿›åŒ–ç­–ç•¥

---

## ğŸ— ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RL-LNS Solver                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   MILP      â”‚    â”‚    GNN      â”‚    â”‚   Qwen2.5   â”‚          â”‚
â”‚  â”‚  Instance   â”‚â”€â”€â”€â–¶â”‚  Tokenizer  â”‚â”€â”€â”€â–¶â”‚   Backbone  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                                      â”‚                â”‚
â”‚         â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    Text     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                    â”‚  Tokenizer  â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Prediction Heads                       â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚   Primal     â”‚  Uncertainty â”‚    Dual      â”‚  Multi-Task â”‚   â”‚
â”‚  â”‚    Head      â”‚     Head     â”‚    Head      â”‚    Head     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Solution: P(x_i = 1) for all i              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®­ç»ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data   â”‚â”€â”€â”€â–¶â”‚  Preprocess  â”‚â”€â”€â”€â–¶â”‚  PyG Graphs  â”‚
â”‚    (JSON)    â”‚    â”‚              â”‚    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Best Model  â”‚â—€â”€â”€â”€â”‚     GRPO     â”‚â—€â”€â”€â”€â”‚   SFT Model  â”‚
â”‚              â”‚    â”‚   Training   â”‚    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â–²
                                               â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚     Physics-Informed SFT Training     â”‚
                           â”‚  L = L_task + Î»â‚L_constr + Î»â‚‚L_int    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ å®‰è£…æŒ‡å—

### ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|---------|---------|
| Python | 3.10+ | 3.10 |
| CUDA | 11.8+ | 12.1+ |
| GPU æ˜¾å­˜ | 16GB | 24GB+ |
| RAM | 32GB | 64GB+ |
| å­˜å‚¨ç©ºé—´ | 50GB | 100GB+ |

### æ–¹å¼ 1: Conda ç¯å¢ƒ (æ¨è)

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-username/RL-LNS.git
cd RL-LNS

# åˆ›å»ºå¹¶æ¿€æ´»ç¯å¢ƒ
conda env create -f environment.yaml
conda activate rl-lns

# å®‰è£… Gurobi (éœ€è¦ License)
conda install -c gurobi gurobi

# éªŒè¯å®‰è£…
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### æ–¹å¼ 2: æ‰‹åŠ¨å®‰è£…

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n rl-lns python=3.10 -y
conda activate rl-lns

# å®‰è£… PyTorch (CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£… PyTorch Geometric
pip install torch_geometric
pip install pyg_lib torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.2.0+cu121.html

# å®‰è£…å…¶ä»–ä¾èµ–
pip install transformers>=4.40.0 accelerate>=0.27.0
pip install bitsandbytes>=0.42.0 peft>=0.8.0
pip install datasets wandb tqdm pyyaml scipy
pip install gurobipy  # éœ€è¦ License
```

### å®‰è£… Flash Attention (å¯é€‰ä½†æ¨è)

```bash
# éœ€è¦ CUDA 11.6+ å’Œæ”¯æŒçš„ GPU (Ampere, Ada, Hopper)
pip install flash-attn --no-build-isolation
```

### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

```bash
# æ–¹å¼ A: è‡ªåŠ¨ä¸‹è½½ (é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä» HuggingFace ä¸‹è½½)
# æ— éœ€é¢å¤–æ“ä½œ

# æ–¹å¼ B: æ‰‹åŠ¨ä¸‹è½½
pip install huggingface_hub
huggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir ./models/Qwen2.5-7B-Instruct
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ•°æ®é¢„å¤„ç†

```bash
# å°†åŸå§‹ JSON æ•°æ®è½¬æ¢ä¸º PyG å›¾æ ¼å¼
python src/main.py preprocess --config configs/data.yaml
```

### 2. SFT è®­ç»ƒ

```bash
# Physics-Informed ç›‘ç£å¾®è°ƒ
python src/main.py train-sft --config configs/training.yaml
```

### 3. GRPO è®­ç»ƒ

```bash
# å¼ºåŒ–å­¦ä¹ å¾®è°ƒ (åœ¨ SFT ä¹‹å)
python src/main.py train-grpo --config configs/training.yaml
```

### 4. æ¨ç†

```bash
# å¯¹æ–°é—®é¢˜è¿›è¡Œé¢„æµ‹
python src/main.py infer --model outputs/sft/best --input problem.lp
```

### 5. å¯å‘å¼è¿›åŒ– (å¯é€‰)

```bash
# è‡ªåŠ¨ç”Ÿæˆ LNS ç®—å­
python src/main.py evolve --config configs/evolution.yaml
```

### å®Œæ•´ç¤ºä¾‹

```python
import torch
from src.model.neuro_solver import NeuroSolver
from src.datalib.preprocess import MILPPreprocessor

# åˆå§‹åŒ–æ¨¡å‹
solver = NeuroSolver(
    backbone="Qwen/Qwen2.5-7B-Instruct",
    mode="gnn",
    load_in_4bit=True,
    device=torch.device("cuda")
)

# åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
solver.load_checkpoint("outputs/sft/best")

# é¢„å¤„ç† MILP å®ä¾‹
preprocessor = MILPPreprocessor()
graph = preprocessor.from_lp_file("problem.lp")

# é¢„æµ‹
with torch.no_grad():
    output = solver(graph)
    probs = output.primal_probs  # P(x_i = 1)
    solution = (probs > 0.5).int()
```

---

## ğŸ“Š æ•°æ®æ ¼å¼

### è¾“å…¥ JSON æ ¼å¼

è®­ç»ƒæ•°æ®åº”ä¸º JSON æ ¼å¼ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«å®Œæ•´çš„ MILP ä¿¡æ¯ï¼š

```json
{
  "problem_id": "instance_001",
  "lp_file": "minimize\n obj: x1 + 2 x2 + 3 x3\nsubject to\n c1: x1 + x2 >= 1\n c2: x2 + x3 <= 2\nbounds\n 0 <= x1 <= 1\n 0 <= x2 <= 1\n 0 <= x3 <= 1\nbinary\n x1 x2 x3\nend",
  "optimal_objective": 1.0,
  "optimal_solution": {
    "x1": 1,
    "x2": 0,
    "x3": 0
  },
  "metadata": {
    "num_variables": 3,
    "num_constraints": 2,
    "problem_type": "set_cover"
  }
}
```

### PyG Graph æ ¼å¼ (é¢„å¤„ç†å)

```python
HeteroData(
  # å˜é‡èŠ‚ç‚¹
  var={
    x=[n_vars, feat_dim],      # ç‰¹å¾: objç³»æ•°, bounds, ç±»å‹, LPè§£ç­‰
    y=[n_vars],                 # æ ‡ç­¾: æœ€ä¼˜è§£
    var_types=[n_vars],         # å˜é‡ç±»å‹
    ...
  },
  
  # çº¦æŸèŠ‚ç‚¹
  con={
    x=[n_constrs, feat_dim],   # ç‰¹å¾: RHS, sense, ç¨€ç–åº¦ç­‰
    ...
  },
  
  # è¾¹ (çº¦æŸ-å˜é‡)
  con__to__var={
    edge_index=[2, n_edges],
    edge_attr=[n_edges, edge_feat_dim],  # ç³»æ•°
  },
  
  # å…ƒä¿¡æ¯
  obj_sense=1,                  # 1=minimize, -1=maximize
  ...
)
```

---

## ğŸ§  æ¨¡å‹æ¶æ„

### GNN Tokenizer

å°† MILP äºŒéƒ¨å›¾ç¼–ç ä¸º Qwen å¯æ¥å—çš„åµŒå…¥åºåˆ—ï¼š

```python
class GNNTokenizer(nn.Module):
    """
    MILP Graph â†’ Embedding Sequence
    
    1. Fourier Feature Encoding: å°†è¿ç»­ç‰¹å¾æ˜ å°„åˆ°é«˜ç»´ç©ºé—´
    2. RWPE: Random Walk Positional Encoding
    3. BipartiteGNN: çº¦æŸ-å˜é‡æ¶ˆæ¯ä¼ é€’
    4. Projection: æŠ•å½±åˆ° Qwen éšå±‚ç»´åº¦ (3584)
    """
    
    # é…ç½®
    gnn_hidden_dim: 256
    gnn_output_dim: 3584  # Match Qwen
    num_layers: 2
    conv_type: "GINEConv"  # or "GATv2Conv"
```

**ç‰¹å¾ç¼–ç **:
- **Fourier Features**: $x \to [\sin(2^k\pi x), \cos(2^k\pi x)]_{k=0}^{L-1}$
- **RWPE**: $\text{diag}(P^k)$ for $k = 1, ..., K$ where $P = D^{-1}A$

### Text Tokenizer

å¤„ç†è¶…é•¿ MILP æ–‡æœ¬è¡¨ç¤ºï¼š

```python
class ChunkedTextEncoder(nn.Module):
    """
    æ”¯æŒ >64K token çš„ MILP æ–‡æœ¬åºåˆ—
    
    1. åˆ†å—: å°†é•¿åºåˆ—åˆ‡åˆ†ä¸ºé‡å å—
    2. ç¼–ç : æ¯å—ç‹¬ç«‹ç¼–ç 
    3. èšåˆ: åŠ æƒå¹³å‡åˆå¹¶å—è¡¨ç¤º
    """
    
    chunk_size: 8192
    chunk_stride: 4096  # 50% é‡å 
```

### Prediction Heads

å¤šä»»åŠ¡é¢„æµ‹å¤´ï¼š

| Head | è¾“å‡º | æè¿° |
|------|-----|------|
| `PredictionHead` | $P(x_i=1)$ | ä¸»é¢„æµ‹å¤´ï¼Œè¾“å‡ºå„å˜é‡ä¸º 1 çš„æ¦‚ç‡ |
| `UncertaintyHead` | $\sigma_i^2$ | é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œç”¨äº LNS é€‰æ‹© |
| `DualHead` | $\pi_j$ | å¯¹å¶å˜é‡é¢„æµ‹ (å¯é€‰) |
| `MultiTaskHead` | ç»„åˆè¾“å‡º | ç»Ÿä¸€çš„å¤šä»»åŠ¡å¤´ |

### NeuroSolver ä¸»æ¨¡å—

```python
class NeuroSolver(nn.Module):
    def forward(self, batch, mode="gnn") -> SolutionOutput:
        # 1. ç¼–ç è¾“å…¥
        if mode == "gnn":
            embeddings = self.gnn_tokenizer(batch)
        else:
            embeddings = self.text_tokenizer(batch)
        
        # 2. Qwen æ¨ç† (RoPE å·²ç¦ç”¨)
        hidden = self.qwen(inputs_embeds=embeddings, position_ids=zeros)
        
        # 3. é¢„æµ‹
        return SolutionOutput(
            primal_probs=self.pred_head(hidden),
            uncertainty=self.uncertainty_head(hidden),
        )
```

---

## ğŸ‹ï¸ è®­ç»ƒæµç¨‹

### Stage 1: Physics-Informed SFT

**ç›®æ ‡**: å­¦ä¹ ä» MILP ç»“æ„åˆ°æœ€ä¼˜è§£çš„æ˜ å°„

**æŸå¤±å‡½æ•°**:
$$\mathcal{L} = \mathcal{L}_{\text{task}} + \lambda_1 \mathcal{L}_{\text{constr}} + \lambda_2 \mathcal{L}_{\text{int}}$$

| æŸå¤±é¡¹ | å…¬å¼ | ä½œç”¨ |
|-------|------|------|
| Task Loss | $-\sum_i [y_i \log p_i + (1-y_i)\log(1-p_i)]$ | é¢„æµ‹ç²¾åº¦ |
| Constraint Loss | $\sum_j \max(0, Ax - b)_j$ | çº¦æŸæ»¡è¶³ |
| Integrality Loss | $\sum_i p_i(1-p_i)$ | æ¨å‘æ•´æ•° |

**é»˜è®¤è¶…å‚æ•°**:
- Learning Rate: 2e-4
- Batch Size: 16 (gradient accumulation)
- Epochs: 3
- $\lambda_1 = 0.1$, $\lambda_2 = 0.01$

### Stage 2: GRPO å¼ºåŒ–å­¦ä¹ 

**ç›®æ ‡**: é€šè¿‡ä¸æ±‚è§£å™¨äº¤äº’è¿›ä¸€æ­¥ä¼˜åŒ–è§£è´¨é‡

**ç®—æ³•**:
1. å¯¹æ¯ä¸ªå®ä¾‹é‡‡æ · $G=16$ ä¸ªå€™é€‰è§£
2. ç”¨ Gurobi è¯„ä¼°æ¯ä¸ªè§£çš„è´¨é‡å’Œå¯è¡Œæ€§
3. è®¡ç®—ç»„å†…ç›¸å¯¹ä¼˜åŠ¿
4. æ›´æ–°ç­–ç•¥æœ€å¤§åŒ–æœŸæœ›å¥–åŠ±

**å¥–åŠ±å‡½æ•°**:
$$r(x) = \begin{cases}
-c^T x & \text{if feasible} \\
-c^T x - \gamma \cdot \text{violation} & \text{otherwise}
\end{cases}$$

**é»˜è®¤è¶…å‚æ•°**:
- Group Size: 16
- Learning Rate: 5e-5
- KL Coefficient: 0.01
- Infeasibility Penalty: 10.0

---

## âš™ï¸ é…ç½®è¯´æ˜

é¡¹ç›®ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶ï¼Œä½äº `configs/` ç›®å½•ã€‚

### model.yaml

```yaml
model:
  name: "Qwen/Qwen2.5-7B-Instruct"
  hidden_size: 3584
  load_in_4bit: true
  lora_r: 64
  lora_alpha: 128
  use_flash_attention: true
  disable_rope: true

gnn:
  hidden_dim: 256
  output_dim: 3584
  num_layers: 2
  conv_type: "GINEConv"

heads:
  hidden_dim: 1024
  enable_uncertainty: true
```

### training.yaml

```yaml
sft:
  batch_size: 1
  gradient_accumulation_steps: 16
  learning_rate: 2.0e-4
  num_epochs: 3
  lambda_constraint: 0.1
  lambda_integrality: 0.01

grpo:
  group_size: 16
  learning_rate: 5.0e-5
  kl_coef: 0.01
```

### data.yaml

```yaml
raw:
  train_json: "data/train_dataset_huge.json"
  val_split_ratio: 0.1

preprocessing:
  compute_lp_relaxation: true
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
RL-LNS/
â”œâ”€â”€ ğŸ“„ README.md              # æœ¬æ–‡ä»¶
â”œâ”€â”€ ğŸ“„ INSTALL.md             # è¯¦ç»†å®‰è£…æŒ‡å—
â”œâ”€â”€ ğŸ“„ LICENSE                # MIT è®¸å¯è¯
â”œâ”€â”€ ğŸ“„ environment.yaml       # Conda ç¯å¢ƒé…ç½®
â”œâ”€â”€ ğŸ“„ requirements.txt       # Pip ä¾èµ–
â”‚
â”œâ”€â”€ ğŸ“‚ configs/               # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ model.yaml            # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ training.yaml         # è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ data.yaml             # æ•°æ®é…ç½®
â”‚   â””â”€â”€ evolution.yaml        # è¿›åŒ–ç®—æ³•é…ç½®
â”‚
â”œâ”€â”€ ğŸ“‚ data/                  # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ train_dataset_huge.json
â”‚   â””â”€â”€ processed/            # é¢„å¤„ç†åçš„æ•°æ®
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
â”‚
â”œâ”€â”€ ğŸ“‚ src/                   # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py               # ä¸»å…¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ datalib/           # æ•°æ®å¤„ç†
â”‚   â”‚   â”œâ”€â”€ preprocess.py     # LP è§£æã€å›¾æ„å»º
â”‚   â”‚   â””â”€â”€ dataset.py        # PyTorch Dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ model/             # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ gnn_tokenizer.py  # GNN ç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ text_tokenizer.py # æ–‡æœ¬ç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ heads.py          # é¢„æµ‹å¤´
â”‚   â”‚   â””â”€â”€ neuro_solver.py   # ä¸»æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ training/          # è®­ç»ƒé€»è¾‘
â”‚   â”‚   â”œâ”€â”€ physics_loss.py   # Physics-Informed æŸå¤±
â”‚   â”‚   â”œâ”€â”€ sft_trainer.py    # SFT è®­ç»ƒå™¨
â”‚   â”‚   â””â”€â”€ grpo_loop.py      # GRPO è®­ç»ƒå™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ evolution/         # å¯å‘å¼è¿›åŒ–
â”‚   â”‚   â”œâ”€â”€ operators.py      # è¿›åŒ–ç®—å­
â”‚   â”‚   â””â”€â”€ eoh.py            # EOH ä¸»ç®—æ³•
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ problems/          # é—®é¢˜å®šä¹‰
â”‚   â”‚   â””â”€â”€ milp.py           # MILP é—®é¢˜æ¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ llm/               # LLM æ¥å£
â”‚   â”‚   â””â”€â”€ api.py            # API è°ƒç”¨å°è£…
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/             # å·¥å…·å‡½æ•°
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ outputs/               # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ sft/                  # SFT æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ grpo/                 # GRPO æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚
â””â”€â”€ ğŸ“‚ experiments/           # å®éªŒè®°å½•
    â””â”€â”€ qwen2.5-7b-sft-milp/
```

---

## ğŸ“š API æ–‡æ¡£

### NeuroSolver

```python
class NeuroSolver(nn.Module):
    """ç»Ÿä¸€çš„ MILP ç¥ç»æ±‚è§£å™¨"""
    
    def __init__(
        self,
        backbone: str = "Qwen/Qwen2.5-7B-Instruct",
        mode: str = "gnn",           # "gnn" | "text" | "both"
        load_in_4bit: bool = True,
        use_flash_attention: bool = True,
        disable_rope: bool = True,
        gnn_hidden_dim: int = 256,
        gnn_num_layers: int = 2,
        lora_r: int = 64,
        lora_alpha: int = 128,
        include_uncertainty: bool = True,
        device: torch.device = None,
    ):
        ...
    
    def forward(
        self,
        batch: Union[HeteroData, Dict],
        mode: Optional[str] = None,
    ) -> SolutionOutput:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            batch: è¾“å…¥æ‰¹æ¬¡ (PyG HeteroData æˆ–æ–‡æœ¬å­—å…¸)
            mode: è¦†ç›–é»˜è®¤æ¨¡å¼
            
        Returns:
            SolutionOutput: åŒ…å« primal_probs, uncertainty ç­‰
        """
        ...
    
    def predict(
        self,
        graph: HeteroData,
        threshold: float = 0.5,
    ) -> torch.Tensor:
        """
        é¢„æµ‹äºŒå…ƒè§£
        
        Args:
            graph: å•ä¸ª MILP å›¾
            threshold: åˆ†ç±»é˜ˆå€¼
            
        Returns:
            solution: äºŒå…ƒè§£å‘é‡
        """
        ...
```

### MILPPreprocessor

```python
class MILPPreprocessor:
    """MILP æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(
        self,
        compute_lp_relaxation: bool = True,
        normalize_features: bool = True,
    ):
        ...
    
    def from_json(self, json_data: Dict) -> HeteroData:
        """ä» JSON æ•°æ®æ„å»ºå›¾"""
        ...
    
    def from_lp_file(self, lp_path: str) -> HeteroData:
        """ä» LP æ–‡ä»¶æ„å»ºå›¾"""
        ...
    
    def process_sample(self, sample: Dict) -> HeteroData:
        """å¤„ç†å•ä¸ªæ ·æœ¬"""
        ...
```

### SFTTrainer

```python
class SFTTrainer:
    """Physics-Informed SFT è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: NeuroSolver,
        train_dataset: Dataset,
        val_dataset: Optional[Dataset] = None,
        learning_rate: float = 2e-4,
        lambda_constraint: float = 0.1,
        lambda_integrality: float = 0.01,
        ...
    ):
        ...
    
    def train(self, num_epochs: int) -> Dict:
        """æ‰§è¡Œè®­ç»ƒ"""
        ...
```

### GRPOTrainer

```python
class GRPOTrainer:
    """GRPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: NeuroSolver,
        group_size: int = 16,
        learning_rate: float = 5e-5,
        kl_coef: float = 0.01,
        infeasibility_penalty: float = 10.0,
        ...
    ):
        ...
    
    def train(self, num_epochs: int) -> Dict:
        """æ‰§è¡Œ GRPO è®­ç»ƒ"""
        ...
```

---

## ğŸ“ˆ å®éªŒç»“æœ

### æ•°æ®é›†

| æ•°æ®é›† | æ ·æœ¬æ•° | å˜é‡èŒƒå›´ | çº¦æŸèŒƒå›´ | é—®é¢˜ç±»å‹ |
|-------|-------|---------|---------|---------|
| train_dataset_huge | ~10K | 50-500 | 20-200 | æ··åˆ |

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|-----|------|
| Accuracy | å˜é‡é¢„æµ‹å‡†ç¡®ç‡ |
| Feasibility Rate | ç”Ÿæˆå¯è¡Œè§£çš„æ¯”ä¾‹ |
| Optimality Gap | ä¸æœ€ä¼˜è§£çš„å·®è· |
| Solve Time | é¢„æµ‹æ—¶é—´ |

### ä¸åŸºå‡†å¯¹æ¯”

*å¾…è¡¥å……å®éªŒç»“æœ*

---

## â“ å¸¸è§é—®é¢˜

### Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

A: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
1. ç¡®ä¿å¯ç”¨ 4-bit é‡åŒ– (`load_in_4bit: true`)
2. å‡å° batch size å¹¶å¢åŠ  gradient accumulation
3. ä½¿ç”¨ gradient checkpointing
4. å‡å° GNN éšå±‚ç»´åº¦

### Q: å¦‚ä½•è·å– Gurobi Licenseï¼Ÿ

A: Gurobi æä¾›å…è´¹å­¦æœ¯ Licenseï¼š
1. è®¿é—® https://www.gurobi.com/academia/academic-program-and-licenses/
2. æ³¨å†Œå­¦æœ¯è´¦å·
3. ä¸‹è½½å¹¶æ¿€æ´» License

### Q: è®­ç»ƒæ—¶ Loss ä¸ä¸‹é™ï¼Ÿ

A: æ£€æŸ¥ä»¥ä¸‹äº‹é¡¹ï¼š
1. å­¦ä¹ ç‡æ˜¯å¦åˆé€‚ (æ¨è 1e-4 ~ 5e-4)
2. æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®
3. æ˜¯å¦æ­£ç¡®åŠ è½½äº†é¢„è®­ç»ƒæƒé‡

### Q: å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®ï¼Ÿ

A: 
1. å‡†å¤‡ JSON æ ¼å¼æ•°æ® (å‚è€ƒæ•°æ®æ ¼å¼ç« èŠ‚)
2. ä¿®æ”¹ `configs/data.yaml` ä¸­çš„è·¯å¾„
3. è¿è¡Œé¢„å¤„ç†: `python src/main.py preprocess --config configs/data.yaml`

### Q: æ”¯æŒå“ªäº› MILP é—®é¢˜ç±»å‹ï¼Ÿ

A: ç†è®ºä¸Šæ”¯æŒä»»æ„ MILP é—®é¢˜ï¼Œä½†è®­ç»ƒæ•°æ®åº”è¦†ç›–ç›®æ ‡é—®é¢˜ç±»å‹ä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚å¸¸è§æ”¯æŒï¼š
- Set Covering / Packing
- Facility Location
- Vehicle Routing (ç®€åŒ–ç‰ˆ)
- Scheduling
- é€šç”¨ 0-1 æ•´æ•°è§„åˆ’

---

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{rl_lns_2024,
  title = {Deep-Structure RL-LNS: Neural Solver for Mixed Integer Linear Programming},
  author = {Your Name},
  year = {2024},
  url = {https://github.com/your-username/RL-LNS}
}
```

### ç›¸å…³å·¥ä½œ

- [Qwen2.5](https://github.com/QwenLM/Qwen2.5) - åŸºåº§å¤§æ¨¡å‹
- [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/) - å›¾ç¥ç»ç½‘ç»œæ¡†æ¶
- [Gurobi](https://www.gurobi.com/) - å•†ä¸š MILP æ±‚è§£å™¨
- [PEFT](https://github.com/huggingface/peft) - å‚æ•°é«˜æ•ˆå¾®è°ƒ

---

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºã€‚

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

---

<p align="center">
  <b>å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æ Issue æˆ– Discussionï¼</b>
</p>